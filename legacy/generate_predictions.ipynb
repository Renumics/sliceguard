{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66214216",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"openai/whisper-tiny\"\n",
    "ACCESS_TOKEN_FILE = \"access_token.txt\"\n",
    "AUDIO_SAVE_DIR = \"audios\"\n",
    "NUM_SAMPLES = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6921bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizer, WhisperForConditionalGeneration, pipeline\n",
    "from renumics import spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68fc9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the acces token for downloading the dataset\n",
    "access_token = Path(ACCESS_TOKEN_FILE).read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b70432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_13_0 (/home/daniel/.cache/huggingface/datasets/mozilla-foundation___common_voice_13_0/en/13.0.0/22809012aac1fc9803eaffc44122e4149043748e93933935d5ea19898587e4d7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9259c008b64bbc8af7fff01ad80ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_13 = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"en\", use_auth_token=access_token, streaming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "987aa72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = len(cv_13[\"train\"])\n",
    "train_indices = np.random.choice(np.arange(train_length), size=NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ea16b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cv_13[\"train\"].select(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c52a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(MODEL_ID)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(MODEL_ID, language=\"en\", task=\"transcribe\")\n",
    "# processor = WhisperProcessor.from_pretrained(MODEL_ID, language=\"en\", task=\"transcribe\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_ID).to(device)\n",
    "\n",
    "# print(model.config.forced_decoder_ids)\n",
    "\n",
    "model.config.forced_decoder_ids = tokenizer.get_decoder_prompt_ids() # Specify the task as we always want to use german and transcribe\n",
    "# model.config.forced_decoder_ids = None\n",
    "# model.config.suppress_tokens = []\n",
    "model.config.language = \"<|en|>\"\n",
    "model.config.task = \"transcribe\"\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=model, tokenizer=tokenizer, feature_extractor=feature_extractor, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ae5129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/20000 [00:00<?, ?it/s]/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.8/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "  0%|                                        | 10/20000 [00:02<43:24,  7.68it/s]/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py:1080: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████| 20000/20000 [44:09<00:00,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "keys_to_save = [\"sentence\", \"up_votes\", \"down_votes\", \"age\", \"gender\", \"accent\", \"locale\", \"segment\", \"variant\"]\n",
    "\n",
    "audio_save_dir = Path(AUDIO_SAVE_DIR)\n",
    "if  not audio_save_dir.is_dir():\n",
    "    audio_save_dir.mkdir()\n",
    "else:\n",
    "    shutil.rmtree(audio_save_dir)\n",
    "    audio_save_dir.mkdir()\n",
    "\n",
    "\n",
    "data = []\n",
    "for s in tqdm(cv):\n",
    "    new_audio = librosa.resample(s[\"audio\"][\"array\"], orig_sr=s[\"audio\"][\"sampling_rate\"], target_sr=16000)\n",
    "    file_stem = str(uuid.uuid4())\n",
    "    cur_data = {}\n",
    "    for k in keys_to_save:\n",
    "        cur_data[k] = s[k]\n",
    "    prediction = pipe(new_audio)[\"text\"]\n",
    "    cur_data[\"prediction\"] = prediction\n",
    "    target_path = audio_save_dir / (file_stem + \".wav\")\n",
    "    cur_data[\"audio\"] = target_path\n",
    "    sf.write(target_path, new_audio, 16000)\n",
    "    data.append(cur_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1af1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "389ae599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"audio\"] = df[\"audio\"].astype(\"string\") # otherwise overflow in serializing json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c20f6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"predictions.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9c527e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
