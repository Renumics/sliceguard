{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4ff8981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers[torch] in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (0.18.2)\n",
      "Requirement already satisfied: datasets in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: invisible_watermark in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: transformers in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (4.30.2)\n",
      "Requirement already satisfied: accelerate in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (0.20.3)\n",
      "Requirement already satisfied: safetensors in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (0.3.1)\n",
      "Requirement already satisfied: requests in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from diffusers[torch]) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from diffusers[torch]) (0.16.4)\n",
      "Requirement already satisfied: Pillow in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from diffusers[torch]) (10.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from diffusers[torch]) (2023.6.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from diffusers[torch]) (6.8.0)\n",
      "Requirement already satisfied: numpy in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from diffusers[torch]) (1.22.4)\n",
      "Requirement already satisfied: filelock in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from diffusers[torch]) (3.12.2)\n",
      "Requirement already satisfied: torch>=1.4 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from diffusers[torch]) (2.0.1)\n",
      "Requirement already satisfied: pandas in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: packaging in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: multiprocess in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from invisible_watermark) (4.8.0.74)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from invisible_watermark) (1.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: psutil in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers[torch]) (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from requests->diffusers[torch]) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from requests->diffusers[torch]) (2.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from requests->diffusers[torch]) (3.4)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (11.7.99)\n",
      "Requirement already satisfied: sympy in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (1.12)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (11.7.101)\n",
      "Requirement already satisfied: networkx in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (3.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (11.7.4.91)\n",
      "Requirement already satisfied: jinja2 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from torch>=1.4->diffusers[torch]) (8.5.0.96)\n",
      "Requirement already satisfied: wheel in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4->diffusers[torch]) (0.40.0)\n",
      "Requirement already satisfied: setuptools in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4->diffusers[torch]) (56.0.0)\n",
      "Requirement already satisfied: lit in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.4->diffusers[torch]) (16.0.6)\n",
      "Requirement already satisfied: cmake in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.4->diffusers[torch]) (3.26.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from importlib-metadata->diffusers[torch]) (3.16.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from jinja2->torch>=1.4->diffusers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages (from sympy->torch>=1.4->diffusers[torch]) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade diffusers[torch] datasets invisible_watermark transformers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e07f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import uuid\n",
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ada6deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/daniel/.cache/huggingface/datasets/Gustavosta___parquet/Gustavosta--Stable-Diffusion-Prompts-eb720eed369c61bb/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b0955a10fe4c2b9681c15abd3fa4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_dataset = datasets.load_dataset(\"Gustavosta/Stable-Diffusion-Prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44dd5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-0.9\", torch_dtype=torch.float16)\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "rf_pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-refiner-0.9\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "rf_pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b76af86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['incev, in style of lee souder, in plastic, dark atmosphere, tilt shift, depth of field,']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['incev, in style of lee souder, in plastic, dark atmosphere, tilt shift, depth of field,']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9c4972f4954f30bbb83525939f1a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['incev, in style of lee souder, in plastic, dark atmosphere, tilt shift, depth of field,']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e81bd96ca5455181e6e9c9ff615815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['trending on art station']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['trending on art station']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c10c779f4f48bd98e48961ffd7d676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['trending on art station']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8635d151482947b5aa81220c9a708643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f52aac30b94371b51de2344a9fc4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58cccbabcd8644019e787d8d9639db77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88c3b8e23c848f89fc536804ce57dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8d2818bbf9408585fc243e370da6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c676d5c310494731ba2a70baf77e8849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3619c856714866bb86eaa9573cbfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6580131fd70645509d5e1116335fd9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a68e85fd3c04a8a84120f065564b693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea59a44069604e22b42169acea4d1b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6859debd9c24ad396a3380ff4837e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9448c4cdeec489b9db8ac9668feb09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1d01f9af4e43b1a161320152e04c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3ed59f001341d38b3227a92169f94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c01d01fb7449e4b480a5f3bd4c85d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef34ca1f14a54c5ea7c7f3b424a66fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2652502c88be4ecdb967fbc2da83995b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09589a4a3c5e4649ad53e8a9753af685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccb8529eab944aba1f51ad098936754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26eec008738e4db1b9e84783feafc931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2b3d32f5c14fc59175bd5cf377f9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be2ea91e620444bb9b8a190b1789270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">12</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>generated_images = []                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> prompt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> prompt_dataset[<span style=\"color: #808000; text-decoration-color: #808000\">\"train\"</span>]:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>prompt = prompt[<span style=\"color: #808000; text-decoration-color: #808000\">\"Prompt\"</span>]                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>12 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>image = pipe(prompt, output_type=<span style=\"color: #808000; text-decoration-color: #808000\">\"latent\"</span>).images                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>image = rf_pipe(prompt=prompt, image=image).images[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages/torch/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages/diffusers/pipelines/stable_diffus</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ion_xl/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pipeline_stable_diffusion_xl.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">778</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">775 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>noise_pred = rescale_noise_cfg(noise_pred, noise_pred_text, guidance   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">776 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># compute the previous noisy sample x_t -&gt; x_t-1</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>778 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>latents = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scheduler.step(noise_pred, t, latents, **extra_step_kwarg   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">779 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">780 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># call the callback, if provided</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">781 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> i == <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(timesteps) - <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> ((i + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>) &gt; num_warmup_steps <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (i + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>) %    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages/diffusers/schedulers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">scheduling_e</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">uler_discrete.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">364</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">361 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(timestep, torch.Tensor):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">362 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>timestep = timestep.to(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.timesteps.device)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">363 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>364 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>step_index = (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.timesteps == timestep).nonzero().item()                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">365 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>sigma = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sigmas[step_index]                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">366 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">367 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>gamma = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">min</span>(s_churn / (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sigmas) - <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>), <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>**<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.5</span> - <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> s_tmin &lt;= sigma &lt;=    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m12\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0mgenerated_images = []                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[94mfor\u001b[0m prompt \u001b[95min\u001b[0m prompt_dataset[\u001b[33m\"\u001b[0m\u001b[33mtrain\u001b[0m\u001b[33m\"\u001b[0m]:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   \u001b[0mprompt = prompt[\u001b[33m\"\u001b[0m\u001b[33mPrompt\u001b[0m\u001b[33m\"\u001b[0m]                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m12 \u001b[2m│   \u001b[0mimage = pipe(prompt, output_type=\u001b[33m\"\u001b[0m\u001b[33mlatent\u001b[0m\u001b[33m\"\u001b[0m).images                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0mimage = rf_pipe(prompt=prompt, image=image).images[\u001b[94m0\u001b[0m]                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages/torch/utils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mdecorate_context\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages/diffusers/pipelines/stable_diffus\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mion_xl/\u001b[0m\u001b[1;33mpipeline_stable_diffusion_xl.py\u001b[0m:\u001b[94m778\u001b[0m in \u001b[92m__call__\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m775 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mnoise_pred = rescale_noise_cfg(noise_pred, noise_pred_text, guidance   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m776 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m777 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# compute the previous noisy sample x_t -> x_t-1\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m778 \u001b[2m│   │   │   │   \u001b[0mlatents = \u001b[96mself\u001b[0m.scheduler.step(noise_pred, t, latents, **extra_step_kwarg   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m779 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m780 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# call the callback, if provided\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m781 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m i == \u001b[96mlen\u001b[0m(timesteps) - \u001b[94m1\u001b[0m \u001b[95mor\u001b[0m ((i + \u001b[94m1\u001b[0m) > num_warmup_steps \u001b[95mand\u001b[0m (i + \u001b[94m1\u001b[0m) %    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/daniel/code/sliceguard/.venv/lib/python3.8/site-packages/diffusers/schedulers/\u001b[0m\u001b[1;33mscheduling_e\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33muler_discrete.py\u001b[0m:\u001b[94m364\u001b[0m in \u001b[92mstep\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m361 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(timestep, torch.Tensor):                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m362 \u001b[0m\u001b[2m│   │   │   \u001b[0mtimestep = timestep.to(\u001b[96mself\u001b[0m.timesteps.device)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m363 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m364 \u001b[2m│   │   \u001b[0mstep_index = (\u001b[96mself\u001b[0m.timesteps == timestep).nonzero().item()                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m365 \u001b[0m\u001b[2m│   │   \u001b[0msigma = \u001b[96mself\u001b[0m.sigmas[step_index]                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m366 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   │   \u001b[0mgamma = \u001b[96mmin\u001b[0m(s_churn / (\u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.sigmas) - \u001b[94m1\u001b[0m), \u001b[94m2\u001b[0m**\u001b[94m0.5\u001b[0m - \u001b[94m1\u001b[0m) \u001b[94mif\u001b[0m s_tmin <= sigma <=    \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_dir = Path(\"images\")\n",
    "if not target_dir.is_dir():\n",
    "    target_dir.mkdir()\n",
    "else:\n",
    "    shutil.rmtree(target_dir)\n",
    "    target_dir.mkdir()\n",
    "\n",
    "prompts = []\n",
    "generated_images = []\n",
    "for prompt in prompt_dataset[\"train\"]:\n",
    "    try:\n",
    "        prompt = prompt[\"Prompt\"]\n",
    "        image = pipe(prompt, output_type=\"latent\").images\n",
    "\n",
    "        image = rf_pipe(prompt=prompt, image=image).images[0]\n",
    "\n",
    "        image_name = f\"{str(uuid.uuid4())}.png\"\n",
    "        image_path = target_dir / image_name\n",
    "        image.save(image_path)\n",
    "        prompts.append(prompt)\n",
    "        generated_images.append(str(image_path))\n",
    "\n",
    "        df = pd.DataFrame(data={\"image\": generated_images, \"prompt\": prompts})\n",
    "        df.to_json(\"sd_dataset.json\", orient=\"records\") # save this after every generation to not loose progress in case of crashing\n",
    "    except:\n",
    "        print(\"An error occured while generating image.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
