{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ae9c85",
   "metadata": {},
   "source": [
    "# Description\n",
    "This notebook will do the following:\n",
    "1. Calculate metrics on the model predictions\n",
    "2. Identify clusters that are classified badly based on metadata and features\n",
    "3. Identify clusters that are classified badly based on unstructured data by using embeddings (+ Train models that assign certain properties to samples based on embeddings)\n",
    "4. Try to infer rules that describe and select problematic samples/clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059f878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN_FILE = \"access_token.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f54919",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa9fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from jiwer import wer\n",
    "from pyannote.audio import Model\n",
    "from pyannote.audio import Inference\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from renumics import spotlight\n",
    "from renumics.spotlight import Audio, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a05c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = Path(ACCESS_TOKEN_FILE).read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc709d9",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2cda29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"predictions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4872623e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "      <th>variant</th>\n",
       "      <th>prediction</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These rights were not reinstated during Nazi r...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>These rates were not reinstated during Nazi r...</td>\n",
       "      <td>audios/f4312eaa-8a00-436f-b99d-89f09bde5739.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The album was recorded at The Forum in Los Ang...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>fourties</td>\n",
       "      <td>male</td>\n",
       "      <td>German English,Non native speaker</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The album was recorded at the forum in Los An...</td>\n",
       "      <td>audios/4d9acf55-f0e1-44e0-8304-5132f89b3b90.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A veteran of the United States Army, Lowenstei...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A veteran of the United States Army, Lawrence...</td>\n",
       "      <td>audios/b3b02b6c-1b2b-4c1e-ad10-c25a2da3c3c5.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The album features heavy involvement from the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>teens</td>\n",
       "      <td>other</td>\n",
       "      <td>Australian English</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The album features heavy involvement from the...</td>\n",
       "      <td>audios/a29ace65-41c3-4ddc-bcd1-bfcca34e0847.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rogers served in the Kentucky and North Caroli...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Roger served in the Kentucky North Carolina A...</td>\n",
       "      <td>audios/9c1ff557-1898-4713-ad14-4536855034e0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>He was by now a regular on the starting fifteen.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>England English</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>He was by now a regular on the starting 15.</td>\n",
       "      <td>audios/8ecff702-b635-42ca-80fe-c4de3255c418.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>The team's home ballpark is Prince George's St...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The team's Home Ball Park is French Georgia S...</td>\n",
       "      <td>audios/11ad111d-7272-48eb-82fd-2f6d4b0a4331.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Even so, the surveys were showing a degraded s...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>fourties</td>\n",
       "      <td>male</td>\n",
       "      <td>German English,Non native speaker</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Even so, the surveys showing a degraded surfi...</td>\n",
       "      <td>audios/b025707d-2a2c-4ae1-a36a-6266c52364f6.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>To date, however, it has no recorded national ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>United States English</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2Date, however, it has now recorded national ...</td>\n",
       "      <td>audios/d5fb80b7-c291-49f3-aae4-1e4908b2f1ca.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Surfers frequent Marina State Beach due to its...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>sixties</td>\n",
       "      <td>male</td>\n",
       "      <td>United States English</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Surface Frequent Remina State Beach due to it...</td>\n",
       "      <td>audios/b70c7732-8db7-4996-b0c4-cdc654cb41c1.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  up_votes  \\\n",
       "0      These rights were not reinstated during Nazi r...         2   \n",
       "1      The album was recorded at The Forum in Los Ang...         4   \n",
       "2      A veteran of the United States Army, Lowenstei...         2   \n",
       "3      The album features heavy involvement from the ...         2   \n",
       "4      Rogers served in the Kentucky and North Caroli...         2   \n",
       "...                                                  ...       ...   \n",
       "19995   He was by now a regular on the starting fifteen.         2   \n",
       "19996  The team's home ballpark is Prince George's St...         2   \n",
       "19997  Even so, the surveys were showing a degraded s...         4   \n",
       "19998  To date, however, it has no recorded national ...         2   \n",
       "19999  Surfers frequent Marina State Beach due to its...         2   \n",
       "\n",
       "       down_votes       age gender                             accent locale  \\\n",
       "0               0                                                         en   \n",
       "1               0  fourties   male  German English,Non native speaker     en   \n",
       "2               0                                                         en   \n",
       "3               1     teens  other                 Australian English     en   \n",
       "4               0                                                         en   \n",
       "...           ...       ...    ...                                ...    ...   \n",
       "19995           0  thirties   male                    England English     en   \n",
       "19996           0                                                         en   \n",
       "19997           2  fourties   male  German English,Non native speaker     en   \n",
       "19998           1  thirties   male              United States English     en   \n",
       "19999           0   sixties   male              United States English     en   \n",
       "\n",
       "      segment variant                                         prediction  \\\n",
       "0                       These rates were not reinstated during Nazi r...   \n",
       "1                       The album was recorded at the forum in Los An...   \n",
       "2                       A veteran of the United States Army, Lawrence...   \n",
       "3                       The album features heavy involvement from the...   \n",
       "4                       Roger served in the Kentucky North Carolina A...   \n",
       "...       ...     ...                                                ...   \n",
       "19995                        He was by now a regular on the starting 15.   \n",
       "19996                   The team's Home Ball Park is French Georgia S...   \n",
       "19997                   Even so, the surveys showing a degraded surfi...   \n",
       "19998                   2Date, however, it has now recorded national ...   \n",
       "19999                   Surface Frequent Remina State Beach due to it...   \n",
       "\n",
       "                                                 audio  \n",
       "0      audios/f4312eaa-8a00-436f-b99d-89f09bde5739.wav  \n",
       "1      audios/4d9acf55-f0e1-44e0-8304-5132f89b3b90.wav  \n",
       "2      audios/b3b02b6c-1b2b-4c1e-ad10-c25a2da3c3c5.wav  \n",
       "3      audios/a29ace65-41c3-4ddc-bcd1-bfcca34e0847.wav  \n",
       "4      audios/9c1ff557-1898-4713-ad14-4536855034e0.wav  \n",
       "...                                                ...  \n",
       "19995  audios/8ecff702-b635-42ca-80fe-c4de3255c418.wav  \n",
       "19996  audios/11ad111d-7272-48eb-82fd-2f6d4b0a4331.wav  \n",
       "19997  audios/b025707d-2a2c-4ae1-a36a-6266c52364f6.wav  \n",
       "19998  audios/d5fb80b7-c291-49f3-aae4-1e4908b2f1ca.wav  \n",
       "19999  audios/b70c7732-8db7-4996-b0c4-cdc654cb41c1.wav  \n",
       "\n",
       "[20000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2c78a",
   "metadata": {},
   "source": [
    "# Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f6e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_error_rates = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    sample_wer = wer(row[\"sentence\"], row[\"prediction\"])\n",
    "    word_error_rates.append(sample_wer)\n",
    "    \n",
    "df[\"wer\"] = word_error_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4703e237",
   "metadata": {},
   "source": [
    "# Compute additional features\n",
    "* Text length, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e75615b",
   "metadata": {},
   "source": [
    "# Compute speaker and text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37cd912d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m speaker_emb_model \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyannote/embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_auth_token\u001b[38;5;241m=\u001b[39maccess_token\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m inference \u001b[38;5;241m=\u001b[39m Inference(speaker_emb_model, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhole\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeaker_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [inference(af)\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m af \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create text embedding model for detecting text based biases\u001b[39;00m\n\u001b[1;32m     10\u001b[0m sentence_embedding_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m speaker_emb_model \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyannote/embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_auth_token\u001b[38;5;241m=\u001b[39maccess_token\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m inference \u001b[38;5;241m=\u001b[39m Inference(speaker_emb_model, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhole\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeaker_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43maf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m af \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create text embedding model for detecting text based biases\u001b[39;00m\n\u001b[1;32m     10\u001b[0m sentence_embedding_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/code/asr-performance-evaluation/.venv/lib/python3.8/site-packages/pyannote/audio/core/inference.py:333\u001b[0m, in \u001b[0;36mInference.__call__\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msliding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslide(waveform, sample_rate)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/code/asr-performance-evaluation/.venv/lib/python3.8/site-packages/pyannote/audio/core/inference.py:190\u001b[0m, in \u001b[0;36mInference.infer\u001b[0;34m(self, chunks)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_oom_error(exception):\n",
      "File \u001b[0;32m~/code/asr-performance-evaluation/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/asr-performance-evaluation/.venv/lib/python3.8/site-packages/pyannote/audio/models/embedding/xvector.py:167\u001b[0m, in \u001b[0;36mXVectorSincNet.forward\u001b[0;34m(self, waveforms, weights)\u001b[0m\n\u001b[1;32m    165\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msincnet(waveforms)\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tdnn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtdnns:\n\u001b[0;32m--> 167\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtdnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats_pool(outputs, weights\u001b[38;5;241m=\u001b[39mweights)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(outputs)\n",
      "File \u001b[0;32m~/code/asr-performance-evaluation/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/asr-performance-evaluation/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/asr-performance-evaluation/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create speaker embedding for detecting speaker based biases\n",
    "speaker_emb_model = Model.from_pretrained(\n",
    "    \"pyannote/embedding\", use_auth_token=access_token\n",
    ")\n",
    "inference = Inference(speaker_emb_model, window=\"whole\")\n",
    "df[\"speaker_embedding\"] = [inference(af).tolist() for af in df[\"audio\"]]\n",
    "\n",
    "\n",
    "# Create text embedding model for detecting text based biases\n",
    "sentence_embedding_model = SentenceTransformer(\n",
    "    \"all-MiniLM-L6-v2\"\n",
    ")\n",
    "sentence_embeddings = sentence_embedding_model.encode(df[\"sentence\"])\n",
    "df[\"text_embedding_ann\"] = [e.tolist() for e in sentence_embeddings]\n",
    "\n",
    "sentence_embeddings = sentence_embedding_model.encode(df[\"prediction\"])\n",
    "df[\"text_embedding_pred\"] = [e.tolist() for e in sentence_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39498f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either save or load embeddings\n",
    "# df.to_json(\"predictions_embs.json\")\n",
    "df= pd.read_json(\"predictions_embs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c46ea973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28e5ae3db3c4642bdf58c6c1344a23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Spotlight running on http://127.0.0.1:40885/'), HBox(children=(Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spotlight.show(df, dtype={\"audio\": Audio, \"text_embedding_ann\": Embedding, \"text_embedding_pred\": Embedding, \"speaker_embedding\": Embedding})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c4484",
   "metadata": {},
   "source": [
    "# Map features to same value if similar in text or by clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8000ef85",
   "metadata": {},
   "source": [
    "to implement later. Would remove some false positives that stem from having different names for the same thing. Matching can be done via string matching or possibly also via speaker embeddings although this is a little unsafe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d91079",
   "metadata": {},
   "source": [
    "# Find critical segments via features/metadata using fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c845a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import MetricFrame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575aa1e9",
   "metadata": {},
   "source": [
    "Mark groups with very few examples and groups that don't work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a196834",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_TO_CHECK = [\"age\", \"gender\", \"accent\"]\n",
    "CNT_RATIO_THRESHOLD = 0.1\n",
    "METRIC_THRESHOLD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ae74147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer_metric(y_true, y_pred):\n",
    "    return np.mean([wer(s_y, s_pred) for s_y, s_pred in zip(y_true, y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97905824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"issue_count_feature_univ\"] = False\n",
    "df[\"issue_fairness_feature_univ\"] = False\n",
    "\n",
    "for feature in FEATURES_TO_CHECK:\n",
    "    mf = MetricFrame(metrics={\"wer\": wer_metric}, y_true=df[\"sentence\"], y_pred=df[\"prediction\"], sensitive_features=df[[feature]])\n",
    "    overall_metric = mf.overall[0]\n",
    "    overall_cnt = len(df)\n",
    "    \n",
    "    group_counts = df[feature].value_counts()\n",
    "    \n",
    "    cnt_fairness_df = mf.by_group.join(group_counts)\n",
    "    \n",
    "    for idx, row in cnt_fairness_df.iterrows():\n",
    "        if row[\"count\"] < (CNT_RATIO_THRESHOLD * (overall_cnt / len(cnt_fairness_df))):\n",
    "            df.loc[df[feature] == idx, \"issue_count_feature_univ\"] = True\n",
    "        metric_diff = (row[\"wer\"] - mf.overall)[0]\n",
    "        if metric_diff > METRIC_THRESHOLD:\n",
    "            df.loc[(df[feature] == idx) & ((df[\"wer\"] - overall_metric) > METRIC_THRESHOLD) , \"issue_fairness_feature_univ\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "562b0e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a64248047746589b52281178c61f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Spotlight running on http://127.0.0.1:44651/'), HBox(children=(Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spotlight.show(df, dtype={\"audio\": Audio, \"text_embedding_ann\": Embedding, \"text_embedding_pred\": Embedding, \"speaker_embedding\": Embedding})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2ae36",
   "metadata": {},
   "source": [
    "# Find interaction effect based unfairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58a4ba",
   "metadata": {},
   "source": [
    "will maybe be implemented later, however multifeature unfairness does sort of cover this, although in a less interpretable way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b242d4",
   "metadata": {},
   "source": [
    "# Find multi feature unfairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682bea4c",
   "metadata": {},
   "source": [
    "ToDo: Support Ordinal features such as age?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26c7345",
   "metadata": {},
   "source": [
    "ToDo: Probably offer something similar with outlier detection in order to not rely on model predictions only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1076e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hnne import HNNE\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8377527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing data of shape (20000, 120)\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded_features = []\n",
    "\n",
    "data = None\n",
    "for feature in FEATURES_TO_CHECK:\n",
    "    feature_data = df[feature]\n",
    "    feature_dtype = feature_data.dtype.name\n",
    "    if feature_dtype in [\"category\", \"string\", \"object\"]:\n",
    "        feature_data = feature_data.values\n",
    "        if len(feature_data.shape) == 1:\n",
    "            feature_data = feature_data[:, np.newaxis]\n",
    "        oh_feature_data = OneHotEncoder(sparse_output=False).fit_transform(feature_data)\n",
    "        \n",
    "        oh_feature = f\"{feature}_oh\"\n",
    "        df[oh_feature] = [f.tolist() for f in oh_feature_data]\n",
    "        one_hot_encoded_features.append(oh_feature)\n",
    "        \n",
    "        if oh_feature_data.shape[1] > 200:\n",
    "            print(\"Warning: Large one hot encoding\")\n",
    "        if data is None:\n",
    "            data = oh_feature_data\n",
    "        else:\n",
    "            data = np.concatenate([data, oh_feature_data], axis=1)\n",
    "\n",
    "print(f\"Reducing data of shape {data.shape}\")\n",
    "hnne = HNNE()\n",
    "projection = hnne.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc6bff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature_projection\"] = [p.tolist() for p in projection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77b5a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = hnne.hierarchy_parameters.partitions\n",
    "partition_sizes = hnne.hierarchy_parameters.partition_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f5c2b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_idx in range(partitions.shape[1]):\n",
    "    df[f\"clustering_{p_idx}\"] = partitions[:, p_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a466152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Basically same as for univariate. maybe generalize the selection rules.\n",
    "df[\"issue_count_feature_muv\"] = False\n",
    "df[\"issue_fairness_feature_muv\"] = False\n",
    "\n",
    "for p_idx in range(partitions.shape[1]):\n",
    "    feature = f\"clustering_{p_idx}\"\n",
    "    mf = MetricFrame(metrics={\"wer\": wer_metric}, y_true=df[\"sentence\"], y_pred=df[\"prediction\"], sensitive_features=df[feature])\n",
    "    overall_metric = mf.overall[0]\n",
    "    overall_cnt = len(df)\n",
    "    \n",
    "    group_counts = df[feature].value_counts()\n",
    "    \n",
    "    cnt_fairness_df = mf.by_group.join(group_counts)\n",
    "    \n",
    "    for idx, row in cnt_fairness_df.iterrows():\n",
    "        if row[\"count\"] < (CNT_RATIO_THRESHOLD * (overall_cnt / len(cnt_fairness_df))):\n",
    "            df.loc[df[feature] == idx, \"issue_count_feature_muv\"] = True\n",
    "        metric_diff = (row[\"wer\"] - mf.overall)[0]\n",
    "        if metric_diff > METRIC_THRESHOLD:\n",
    "            df.loc[(df[feature] == idx) & ((df[\"wer\"] - overall_metric) > METRIC_THRESHOLD) , \"issue_fairness_feature_muv\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e4e5ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1095f2d6a8664380b39064a600cfe0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Spotlight running on http://127.0.0.1:40963/'), HBox(children=(Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "dtype_dict = {\"audio\": Audio,\n",
    "                          \"text_embedding_ann\": Embedding,\n",
    "                          \"text_embedding_pred\": Embedding,\n",
    "                          \"speaker_embedding\": Embedding,\n",
    "                          \"feature_projection\": Embedding}\n",
    "for f in one_hot_encoded_features:\n",
    "    dtype_dict[f] = Embedding\n",
    "spotlight.show(df, dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "430cede6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "      <th>variant</th>\n",
       "      <th>prediction</th>\n",
       "      <th>audio</th>\n",
       "      <th>wer</th>\n",
       "      <th>speaker_embedding</th>\n",
       "      <th>text_embedding_ann</th>\n",
       "      <th>text_embedding_pred</th>\n",
       "      <th>feature_projection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These rights were not reinstated during Nazi r...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>These rates were not reinstated during Nazi r...</td>\n",
       "      <td>audios/f4312eaa-8a00-436f-b99d-89f09bde5739.wav</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>[0.48153656720000004, 51.8129119873, 5.9365177...</td>\n",
       "      <td>[-0.012564905000000001, 0.07866118100000001, -...</td>\n",
       "      <td>[0.045725155600000005, 0.0401938185, -0.009251...</td>\n",
       "      <td>[4.0436070388160275, -0.6697940767497417]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The album was recorded at The Forum in Los Ang...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>fourties</td>\n",
       "      <td>male</td>\n",
       "      <td>German English,Non native speaker</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The album was recorded at the forum in Los An...</td>\n",
       "      <td>audios/4d9acf55-f0e1-44e0-8304-5132f89b3b90.wav</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>[-45.7863960266, 27.8419494629, 24.8209590912,...</td>\n",
       "      <td>[0.043684762, -0.061664264600000004, -0.031076...</td>\n",
       "      <td>[0.043684724700000004, -0.0616642721, -0.03107...</td>\n",
       "      <td>[-2.0917964089262697, -3.120701493348443]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A veteran of the United States Army, Lowenstei...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A veteran of the United States Army, Lawrence...</td>\n",
       "      <td>audios/b3b02b6c-1b2b-4c1e-ad10-c25a2da3c3c5.wav</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>[27.2776126862, 59.8899421692, 46.0985794067, ...</td>\n",
       "      <td>[0.0312165152, 0.0511640087, 0.007571328400000...</td>\n",
       "      <td>[-0.0033591513, 0.0733282343, -0.0340879634000...</td>\n",
       "      <td>[4.0436070388160275, -0.6697940767497439]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The album features heavy involvement from the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>teens</td>\n",
       "      <td>other</td>\n",
       "      <td>Australian English</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The album features heavy involvement from the...</td>\n",
       "      <td>audios/a29ace65-41c3-4ddc-bcd1-bfcca34e0847.wav</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>[97.3435974121, -15.7048883438, 17.7362995148,...</td>\n",
       "      <td>[0.0134361545, -0.0262203366, -0.0016528621, 0...</td>\n",
       "      <td>[0.0047452236, -0.0391150378, -0.0390664600000...</td>\n",
       "      <td>[1.5350056288722154, 0.9490219857053079]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rogers served in the Kentucky and North Caroli...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Roger served in the Kentucky North Carolina A...</td>\n",
       "      <td>audios/9c1ff557-1898-4713-ad14-4536855034e0.wav</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>[12.9974803925, 6.7657399178, 11.4522953033, 2...</td>\n",
       "      <td>[-0.0807927251, 0.024178849500000002, -0.01822...</td>\n",
       "      <td>[-0.10895261910000001, 0.0415730923, 0.0069424...</td>\n",
       "      <td>[4.0436070388160275, -0.669794076749741]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>He was by now a regular on the starting fifteen.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>England English</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>He was by now a regular on the starting 15.</td>\n",
       "      <td>audios/8ecff702-b635-42ca-80fe-c4de3255c418.wav</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>[-17.9059429169, -0.9018530250000001, -8.17157...</td>\n",
       "      <td>[0.0664717183, 0.0155410888, -0.0084157716, -0...</td>\n",
       "      <td>[0.0297332369, -0.0002950175, -0.0190396663, -...</td>\n",
       "      <td>[-1.65164614654853, -0.2811413119269855]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>The team's home ballpark is Prince George's St...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The team's Home Ball Park is French Georgia S...</td>\n",
       "      <td>audios/11ad111d-7272-48eb-82fd-2f6d4b0a4331.wav</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[23.8514080048, 17.4905891418, 33.3259124756, ...</td>\n",
       "      <td>[0.0723667592, 0.0241533518, 0.0584359132, -0....</td>\n",
       "      <td>[-0.0026451834000000003, 0.0213504396, 0.00195...</td>\n",
       "      <td>[4.0436070388160275, -0.6697940767497415]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Even so, the surveys were showing a degraded s...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>fourties</td>\n",
       "      <td>male</td>\n",
       "      <td>German English,Non native speaker</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Even so, the surveys showing a degraded surfi...</td>\n",
       "      <td>audios/b025707d-2a2c-4ae1-a36a-6266c52364f6.wav</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>[-30.3821411133, 24.6229801178, 10.1435604095,...</td>\n",
       "      <td>[-0.013233019, -0.0332972743, 0.100652054, 0.0...</td>\n",
       "      <td>[-0.0102967089, -0.0505346283, 0.097537227, 0....</td>\n",
       "      <td>[-2.0917964089262733, -3.1207014933484363]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>To date, however, it has no recorded national ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>United States English</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2Date, however, it has now recorded national ...</td>\n",
       "      <td>audios/d5fb80b7-c291-49f3-aae4-1e4908b2f1ca.wav</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>[46.5772247314, 3.6495623589, 7.2550296783, 35...</td>\n",
       "      <td>[-0.0062213158, -0.016576109500000002, -0.0802...</td>\n",
       "      <td>[-0.0190290306, -0.033360444, -0.02469551, -0....</td>\n",
       "      <td>[-1.693252485180613, -0.217159516935523]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Surfers frequent Marina State Beach due to its...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>sixties</td>\n",
       "      <td>male</td>\n",
       "      <td>United States English</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Surface Frequent Remina State Beach due to it...</td>\n",
       "      <td>audios/b70c7732-8db7-4996-b0c4-cdc654cb41c1.wav</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>[0.28366631270000003, 29.1069831848, 20.356805...</td>\n",
       "      <td>[-0.0218563173, -0.050008665800000004, 0.04445...</td>\n",
       "      <td>[0.0182144251, -0.0506648533, 0.09429512920000...</td>\n",
       "      <td>[-1.14055152643181, 0.3328713584720103]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  up_votes  \\\n",
       "0      These rights were not reinstated during Nazi r...         2   \n",
       "1      The album was recorded at The Forum in Los Ang...         4   \n",
       "2      A veteran of the United States Army, Lowenstei...         2   \n",
       "3      The album features heavy involvement from the ...         2   \n",
       "4      Rogers served in the Kentucky and North Caroli...         2   \n",
       "...                                                  ...       ...   \n",
       "19995   He was by now a regular on the starting fifteen.         2   \n",
       "19996  The team's home ballpark is Prince George's St...         2   \n",
       "19997  Even so, the surveys were showing a degraded s...         4   \n",
       "19998  To date, however, it has no recorded national ...         2   \n",
       "19999  Surfers frequent Marina State Beach due to its...         2   \n",
       "\n",
       "       down_votes       age gender                             accent locale  \\\n",
       "0               0                                                         en   \n",
       "1               0  fourties   male  German English,Non native speaker     en   \n",
       "2               0                                                         en   \n",
       "3               1     teens  other                 Australian English     en   \n",
       "4               0                                                         en   \n",
       "...           ...       ...    ...                                ...    ...   \n",
       "19995           0  thirties   male                    England English     en   \n",
       "19996           0                                                         en   \n",
       "19997           2  fourties   male  German English,Non native speaker     en   \n",
       "19998           1  thirties   male              United States English     en   \n",
       "19999           0   sixties   male              United States English     en   \n",
       "\n",
       "      segment variant                                         prediction  \\\n",
       "0                       These rates were not reinstated during Nazi r...   \n",
       "1                       The album was recorded at the forum in Los An...   \n",
       "2                       A veteran of the United States Army, Lawrence...   \n",
       "3                       The album features heavy involvement from the...   \n",
       "4                       Roger served in the Kentucky North Carolina A...   \n",
       "...       ...     ...                                                ...   \n",
       "19995                        He was by now a regular on the starting 15.   \n",
       "19996                   The team's Home Ball Park is French Georgia S...   \n",
       "19997                   Even so, the surveys showing a degraded surfi...   \n",
       "19998                   2Date, however, it has now recorded national ...   \n",
       "19999                   Surface Frequent Remina State Beach due to it...   \n",
       "\n",
       "                                                 audio       wer  \\\n",
       "0      audios/f4312eaa-8a00-436f-b99d-89f09bde5739.wav  0.250000   \n",
       "1      audios/4d9acf55-f0e1-44e0-8304-5132f89b3b90.wav  0.200000   \n",
       "2      audios/b3b02b6c-1b2b-4c1e-ad10-c25a2da3c3c5.wav  0.214286   \n",
       "3      audios/a29ace65-41c3-4ddc-bcd1-bfcca34e0847.wav  0.400000   \n",
       "4      audios/9c1ff557-1898-4713-ad14-4536855034e0.wav  0.181818   \n",
       "...                                                ...       ...   \n",
       "19995  audios/8ecff702-b635-42ca-80fe-c4de3255c418.wav  0.100000   \n",
       "19996  audios/11ad111d-7272-48eb-82fd-2f6d4b0a4331.wav  0.625000   \n",
       "19997  audios/b025707d-2a2c-4ae1-a36a-6266c52364f6.wav  0.153846   \n",
       "19998  audios/d5fb80b7-c291-49f3-aae4-1e4908b2f1ca.wav  0.300000   \n",
       "19999  audios/b70c7732-8db7-4996-b0c4-cdc654cb41c1.wav  0.400000   \n",
       "\n",
       "                                       speaker_embedding  \\\n",
       "0      [0.48153656720000004, 51.8129119873, 5.9365177...   \n",
       "1      [-45.7863960266, 27.8419494629, 24.8209590912,...   \n",
       "2      [27.2776126862, 59.8899421692, 46.0985794067, ...   \n",
       "3      [97.3435974121, -15.7048883438, 17.7362995148,...   \n",
       "4      [12.9974803925, 6.7657399178, 11.4522953033, 2...   \n",
       "...                                                  ...   \n",
       "19995  [-17.9059429169, -0.9018530250000001, -8.17157...   \n",
       "19996  [23.8514080048, 17.4905891418, 33.3259124756, ...   \n",
       "19997  [-30.3821411133, 24.6229801178, 10.1435604095,...   \n",
       "19998  [46.5772247314, 3.6495623589, 7.2550296783, 35...   \n",
       "19999  [0.28366631270000003, 29.1069831848, 20.356805...   \n",
       "\n",
       "                                      text_embedding_ann  \\\n",
       "0      [-0.012564905000000001, 0.07866118100000001, -...   \n",
       "1      [0.043684762, -0.061664264600000004, -0.031076...   \n",
       "2      [0.0312165152, 0.0511640087, 0.007571328400000...   \n",
       "3      [0.0134361545, -0.0262203366, -0.0016528621, 0...   \n",
       "4      [-0.0807927251, 0.024178849500000002, -0.01822...   \n",
       "...                                                  ...   \n",
       "19995  [0.0664717183, 0.0155410888, -0.0084157716, -0...   \n",
       "19996  [0.0723667592, 0.0241533518, 0.0584359132, -0....   \n",
       "19997  [-0.013233019, -0.0332972743, 0.100652054, 0.0...   \n",
       "19998  [-0.0062213158, -0.016576109500000002, -0.0802...   \n",
       "19999  [-0.0218563173, -0.050008665800000004, 0.04445...   \n",
       "\n",
       "                                     text_embedding_pred  \\\n",
       "0      [0.045725155600000005, 0.0401938185, -0.009251...   \n",
       "1      [0.043684724700000004, -0.0616642721, -0.03107...   \n",
       "2      [-0.0033591513, 0.0733282343, -0.0340879634000...   \n",
       "3      [0.0047452236, -0.0391150378, -0.0390664600000...   \n",
       "4      [-0.10895261910000001, 0.0415730923, 0.0069424...   \n",
       "...                                                  ...   \n",
       "19995  [0.0297332369, -0.0002950175, -0.0190396663, -...   \n",
       "19996  [-0.0026451834000000003, 0.0213504396, 0.00195...   \n",
       "19997  [-0.0102967089, -0.0505346283, 0.097537227, 0....   \n",
       "19998  [-0.0190290306, -0.033360444, -0.02469551, -0....   \n",
       "19999  [0.0182144251, -0.0506648533, 0.09429512920000...   \n",
       "\n",
       "                               feature_projection  \n",
       "0       [4.0436070388160275, -0.6697940767497417]  \n",
       "1       [-2.0917964089262697, -3.120701493348443]  \n",
       "2       [4.0436070388160275, -0.6697940767497439]  \n",
       "3        [1.5350056288722154, 0.9490219857053079]  \n",
       "4        [4.0436070388160275, -0.669794076749741]  \n",
       "...                                           ...  \n",
       "19995    [-1.65164614654853, -0.2811413119269855]  \n",
       "19996   [4.0436070388160275, -0.6697940767497415]  \n",
       "19997  [-2.0917964089262733, -3.1207014933484363]  \n",
       "19998    [-1.693252485180613, -0.217159516935523]  \n",
       "19999     [-1.14055152643181, 0.3328713584720103]  \n",
       "\n",
       "[20000 rows x 16 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba377268",
   "metadata": {},
   "source": [
    "# Find hidden stratification based unfairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da3c78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39f5ce1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent',\n",
       "       'locale', 'segment', 'variant', 'prediction', 'audio', 'wer',\n",
       "       'speaker_embedding', 'text_embedding_ann', 'text_embedding_pred',\n",
       "       'issue_count_feature_univ', 'issue_fairness_feature_univ', 'age_oh',\n",
       "       'gender_oh', 'accent_oh', 'feature_projection', 'clustering_0',\n",
       "       'clustering_1', 'clustering_2', 'issue_count_feature_muv',\n",
       "       'issue_fairness_feature_muv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cda3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_embedding_data = np.vstack(df[\"speaker_embedding\"])\n",
    "text_embedding_data = np.vstack(df[\"text_embedding_ann\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9af19d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing data of shape (20000, 512)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reducing data of shape {speaker_embedding_data.shape}\")\n",
    "speaker_hnne = HNNE()\n",
    "speaker_projection = speaker_hnne.fit_transform(speaker_embedding_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e4bdcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"speaker_projection\"] = [p.tolist() for p in speaker_projection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a0d344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_partitions = speaker_hnne.hierarchy_parameters.partitions\n",
    "speaker_partition_sizes = speaker_hnne.hierarchy_parameters.partition_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "201fe969",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_idx in range(speaker_partitions.shape[1]):\n",
    "    df[f\"speaker_clustering_{p_idx}\"] = speaker_partitions[:, p_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfdf4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Same again here. Definitely generalize this\n",
    "df[\"issue_count_speaker_emb\"] = False\n",
    "df[\"issue_fairness_speaker_emb\"] = False\n",
    "\n",
    "for p_idx in range(speaker_partitions.shape[1]):\n",
    "    feature = f\"speaker_clustering_{p_idx}\"\n",
    "    mf = MetricFrame(metrics={\"wer\": wer_metric}, y_true=df[\"sentence\"], y_pred=df[\"prediction\"], sensitive_features=df[feature])\n",
    "    overall_metric = mf.overall[0]\n",
    "    overall_cnt = len(df)\n",
    "    \n",
    "    group_counts = df[feature].value_counts()\n",
    "    \n",
    "    cnt_fairness_df = mf.by_group.join(group_counts)\n",
    "    \n",
    "    for idx, row in cnt_fairness_df.iterrows():\n",
    "        if row[\"count\"] < (CNT_RATIO_THRESHOLD * (overall_cnt / len(cnt_fairness_df))):\n",
    "            df.loc[df[feature] == idx, \"issue_count_speaker_emb\"] = True\n",
    "        metric_diff = (row[\"wer\"] - mf.overall)[0]\n",
    "        if metric_diff > METRIC_THRESHOLD:\n",
    "            df.loc[(df[feature] == idx) & ((df[\"wer\"] - overall_metric) > METRIC_THRESHOLD) , \"issue_fairness_speaker_emb\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcaef587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f379ad63bc74aa1a8f22b79c068db76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Spotlight running on http://127.0.0.1:34575/'), HBox(children=(Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:274: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/home/daniel/code/asr-performance-evaluation/.venv/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:274: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "spotlight.show(df, dtype={\"audio\": Audio,\n",
    "                          \"text_embedding_ann\": Embedding,\n",
    "                          \"text_embedding_pred\": Embedding,\n",
    "                          \"speaker_embedding\": Embedding,\n",
    "                          \"feature_projection\": Embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1f2497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing data of shape (20000, 384)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reducing data of shape {text_embedding_data.shape}\")\n",
    "text_hnne = HNNE()\n",
    "text_projection = text_hnne.fit_transform(text_embedding_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81961c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_projection\"] = [p.tolist() for p in text_projection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ae4f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_partitions = text_hnne.hierarchy_parameters.partitions\n",
    "text_partition_sizes = text_hnne.hierarchy_parameters.partition_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bd865d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_idx in range(text_partitions.shape[1]):\n",
    "    df[f\"text_clustering_{p_idx}\"] = text_partitions[:, p_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb3b043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        wer\n",
      "text_clustering_4          \n",
      "0                  0.226748\n",
      "1                  0.281987\n",
      "2                  0.279186\n",
      "                        wer\n",
      "text_clustering_3          \n",
      "0                  0.205555\n",
      "1                  0.280525\n",
      "2                  0.292410\n",
      "3                  0.244693\n",
      "4                  0.278659\n",
      "5                  0.230866\n",
      "6                  0.291258\n",
      "7                  0.243022\n",
      "8                  0.365301\n",
      "9                  0.274099\n",
      "10                 0.264149\n",
      "11                 0.299902\n",
      "12                 0.272566\n",
      "13                 0.226087\n",
      "14                 0.279822\n",
      "15                 0.280920\n",
      "                        wer\n",
      "text_clustering_2          \n",
      "0                  0.184015\n",
      "1                  0.288433\n",
      "2                  0.304552\n",
      "3                  0.259441\n",
      "4                  0.249907\n",
      "...                     ...\n",
      "67                 0.339443\n",
      "68                 0.187876\n",
      "69                 0.241693\n",
      "70                 0.251045\n",
      "71                 0.117100\n",
      "\n",
      "[72 rows x 1 columns]\n",
      "                        wer\n",
      "text_clustering_1          \n",
      "0                  0.185449\n",
      "1                  0.307950\n",
      "2                  0.447646\n",
      "3                  0.268067\n",
      "4                  0.257391\n",
      "...                     ...\n",
      "440                0.308090\n",
      "441                0.152778\n",
      "442                0.178030\n",
      "443                0.307769\n",
      "444                0.210317\n",
      "\n",
      "[445 rows x 1 columns]\n",
      "                        wer\n",
      "text_clustering_0          \n",
      "0                  0.165843\n",
      "1                  0.284411\n",
      "2                  0.229678\n",
      "3                  0.370313\n",
      "4                  0.226380\n",
      "...                     ...\n",
      "3262               0.428571\n",
      "3263               0.437500\n",
      "3264               0.157143\n",
      "3265               0.450000\n",
      "3266               0.200000\n",
      "\n",
      "[3267 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# ToDo: Same again here. Definitely generalize this\n",
    "# Idea for hierarchy merging. Go down from coarsest clusters. If going more finegranular makes the metric significantly worse assign to finer hierarchy level.\n",
    "df[\"issue_count_text_emb\"] = False\n",
    "df[\"issue_fairness_text_emb\"] = False\n",
    "df[\"cur_hierarchy\"] = -1\n",
    "df[\"cur_cluster\"] = -1\n",
    "\n",
    "for p_num in range(text_partitions.shape[1]):\n",
    "    p_idx = text_partitions.shape[1] - p_num - 1\n",
    "    feature = f\"text_clustering_{p_idx}\"\n",
    "    mf = MetricFrame(metrics={\"wer\": wer_metric}, y_true=df[\"sentence\"], y_pred=df[\"prediction\"], sensitive_features=df[feature])\n",
    "    print(mf.by_group)\n",
    "    overall_metric = mf.overall[0]\n",
    "    overall_cnt = len(df)\n",
    "    \n",
    "    group_counts = df[feature].value_counts()\n",
    "    \n",
    "    cnt_fairness_df = mf.by_group.join(group_counts)\n",
    "    \n",
    "    for idx, row in cnt_fairness_df.iterrows():\n",
    "        if row[\"count\"] < (CNT_RATIO_THRESHOLD * (overall_cnt / len(cnt_fairness_df))):\n",
    "            df.loc[df[feature] == idx, \"issue_count_text_emb\"] = True\n",
    "        metric_diff = (row[\"wer\"] - mf.overall)[0]\n",
    "        if metric_diff > METRIC_THRESHOLD:\n",
    "            df.loc[(df[feature] == idx) & ((df[\"wer\"] - overall_metric) > METRIC_THRESHOLD) , \"issue_fairness_text_emb\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e30336b",
   "metadata": {},
   "source": [
    "ToDo: Treat hiearchy levels in clustering in some way. like this it doesn't make much sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d03f04fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2f87b9a6b745c2a32a6010aff9ff39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Spotlight running on http://127.0.0.1:32927/'), HBox(children=(Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtype_dict = {\"audio\": Audio,\n",
    "                          \"text_embedding_ann\": Embedding,\n",
    "                          \"text_embedding_pred\": Embedding,\n",
    "                          \"speaker_embedding\": Embedding,\n",
    "                          \"feature_projection\": Embedding}\n",
    "for f in one_hot_encoded_features:\n",
    "    dtype_dict[f] = Embedding\n",
    "spotlight.show(df, dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f95e82",
   "metadata": {},
   "source": [
    "# Find the most probable cause for model problem based on simple detectors (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34421500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
