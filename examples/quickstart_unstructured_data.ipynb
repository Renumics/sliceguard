{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sliceguard – Find critical data segments in your data (fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sliceguard is a python library for quickly finding **critical data slices** like outliers, errors, or biases. It works on **structured** and **unstructured** data.\n",
    "\n",
    "This notebook showcases especially the unstructured data case, so if you have tabular data instead have a look at [this notebook](examples/quickstart_structured_data.ipynb) instead\n",
    "\n",
    "It is interesting for you if you want to do the following:\n",
    "1. Find **performance issues** of your machine learning model.\n",
    "2. Find **anomalies and inconsistencies** in your data.\n",
    "3. Quickly **explore** your data using an interactive report to generate **insights**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook install and import sliceguard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sliceguard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sliceguard import SliceGuard\n",
    "from sliceguard.data import from_huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now download the demo dataset with our utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = from_huggingface(\"Matthijs/snacks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have the following dataframe containing an image column with a path to the raw image on the harddrive, a label and a split marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>apple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>apple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>apple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>apple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>apple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>watermelon</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>watermelon</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>watermelon</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>watermelon</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>watermelon</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6745 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 image       label       split\n",
       "0    /home/daniel/.cache/huggingface/datasets/downl...       apple       train\n",
       "1    /home/daniel/.cache/huggingface/datasets/downl...       apple       train\n",
       "2    /home/daniel/.cache/huggingface/datasets/downl...       apple       train\n",
       "3    /home/daniel/.cache/huggingface/datasets/downl...       apple       train\n",
       "4    /home/daniel/.cache/huggingface/datasets/downl...       apple       train\n",
       "..                                                 ...         ...         ...\n",
       "950  /home/daniel/.cache/huggingface/datasets/downl...  watermelon  validation\n",
       "951  /home/daniel/.cache/huggingface/datasets/downl...  watermelon  validation\n",
       "952  /home/daniel/.cache/huggingface/datasets/downl...  watermelon  validation\n",
       "953  /home/daniel/.cache/huggingface/datasets/downl...  watermelon  validation\n",
       "954  /home/daniel/.cache/huggingface/datasets/downl...  watermelon  validation\n",
       "\n",
       "[6745 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for larger error groups and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature image was inferred as referring to raw data. If this is not the case, please specify in feature_types!\n",
      "Using default model for computing embeddings for feature image.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/code/sliceguard/.venv/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91b6f1266b74db382cc14b55e5b425c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You didn't supply ground-truth labels and predictions. Will fit outlier detection model to find anomal slices instead.\n",
      "The overall metric value is 0.47909346882516424\n",
      "For outlier detection mode metric_mode will be set to min if not specified otherwise.\n",
      "Using 20 as maximum slice number to return.\n",
      "Using drop as sorting criterion for the slices to return.\n",
      "      metric  support      drop  level  drop+support\n",
      "89  0.648239        2  0.169146      3      0.338291\n",
      "47  0.633935        3  0.154842      3      0.464525\n",
      "26  0.632910        2  0.153816      3      0.307633\n",
      "64  0.628950        4  0.149856      3      0.599425\n",
      "16  0.619255       11  0.140161      2      1.541776\n",
      "..       ...      ...       ...    ...           ...\n",
      "43  0.426496        8 -0.052598      3     -0.420783\n",
      "13  0.425738        4 -0.053355      3     -0.213422\n",
      "61  0.420830        5 -0.058263      3     -0.291315\n",
      "85  0.419886        2 -0.059208      3     -0.118416\n",
      "83  0.419882        2 -0.059211      3     -0.118423\n",
      "\n",
      "[136 rows x 5 columns]\n",
      "Identified 20 problematic slices.\n"
     ]
    }
   ],
   "source": [
    "sg = SliceGuard()\n",
    "issues = sg.find_issues(df, [\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                  image       label  \\\n",
       " 578   /home/daniel/.cache/huggingface/datasets/downl...      muffin   \n",
       " 2661  /home/daniel/.cache/huggingface/datasets/downl...       juice   \n",
       " 645   /home/daniel/.cache/huggingface/datasets/downl...        cake   \n",
       " 2851  /home/daniel/.cache/huggingface/datasets/downl...      muffin   \n",
       " 801   /home/daniel/.cache/huggingface/datasets/downl...       salad   \n",
       " ...                                                 ...         ...   \n",
       " 807   /home/daniel/.cache/huggingface/datasets/downl...  strawberry   \n",
       " 3977  /home/daniel/.cache/huggingface/datasets/downl...       salad   \n",
       " 1017  /home/daniel/.cache/huggingface/datasets/downl...      carrot   \n",
       " 2937  /home/daniel/.cache/huggingface/datasets/downl...      muffin   \n",
       " 209   /home/daniel/.cache/huggingface/datasets/downl...      carrot   \n",
       " \n",
       "            split                                       sg_emb_image  sg_y_pred  \n",
       " 578         test  [-0.007233772426843643, 0.7412320971488953, 1....   0.423718  \n",
       " 2661       train  [-0.1278814971446991, 2.048302173614502, 0.926...   0.458901  \n",
       " 645        train  [0.5971614718437195, -0.043301552534103394, 0....   0.422491  \n",
       " 2851       train  [-0.07590066641569138, -0.6328465938568115, 0....   0.417518  \n",
       " 801   validation  [-1.8350385427474976, -0.7565639019012451, -0....   0.516684  \n",
       " ...          ...                                                ...        ...  \n",
       " 807         test  [-0.2393253892660141, 0.6468426585197449, -0.7...   0.423526  \n",
       " 3977       train  [-1.5951948165893555, 1.7076865434646606, -0.6...   0.494482  \n",
       " 1017       train  [-1.0045827627182007, -0.8392734527587891, -2....   0.476603  \n",
       " 2937       train  [-0.30244505405426025, -0.541172444820404, 0.6...   0.433483  \n",
       " 209   validation  [0.3581114113330841, 0.7689638137817383, 1.473...   0.453360  \n",
       " \n",
       " [400 rows x 5 columns],\n",
       " [DataIssue(severity='medium', title='0.65 -> image, (1.00)', rows=[216, 307], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.63 -> image, (1.00)', rows=[69, 162, 320], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.63 -> image, (1.00)', rows=[29, 311], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.63 -> image, (1.00)', rows=[106, 237, 254, 262], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.62 -> image, (1.00)', rows=[29, 45, 124, 139, 163, 184, 266, 268, 277, 311, 375], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.62 -> image, (1.00)', rows=[5, 44, 69, 88, 106, 122, 162, 172, 196, 213, 215, 216, 220, 237, 253, 254, 262, 274, 292, 307, 320, 364, 393], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.62 -> image, (1.00)', rows=[45, 124, 139, 163, 184, 266, 268, 277, 375], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.62 -> image, (1.00)', rows=[122, 196, 253, 274], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.60 -> image, (1.00)', rows=[5, 44, 88, 172, 213, 215, 220, 292, 364, 393], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.55 -> image, (1.00)', rows=[187, 248, 270, 306, 373], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.55 -> image, (1.00)', rows=[102, 316, 356], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.53 -> image, (1.00)', rows=[9, 11, 201, 385], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.52 -> image, (1.00)', rows=[210, 221, 260, 297, 315, 394], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.52 -> image, (1.00)', rows=[98, 183, 271, 296, 367], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.52 -> image, (1.00)', rows=[77, 81, 94, 114, 167, 175, 176, 187, 190, 226, 239, 248, 270, 295, 306, 360, 373], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.52 -> image, (1.00)', rows=[4, 43, 119, 186, 207], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.51 -> image, (1.00)', rows=[4, 9, 11, 33, 43, 98, 102, 108, 119, 183, 186, 201, 207, 257, 271, 296, 316, 332, 333, 335, 344, 356, 367, 382, 385, 396], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.51 -> image, (1.00)', rows=[46, 185, 210, 221, 225, 227, 244, 260, 297, 315, 348, 394], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.51 -> image, (1.00)', rows=[335, 382], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.51 -> image, (1.00)', rows=[77, 167, 175, 190, 226, 239, 360], columns=['image'], description='')])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let sliceguard train a model to pinpoint problems even better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an own advanced model and find its weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
