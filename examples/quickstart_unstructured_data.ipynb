{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sliceguard – Find critical data segments in your data (fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sliceguard is a python library for quickly finding **critical data slices** like outliers, errors, or biases. It works on **structured** and **unstructured** data.\n",
    "\n",
    "This notebook showcases especially the unstructured data case, so if you have tabular data instead have a look at [this notebook](examples/quickstart_structured_data.ipynb) instead\n",
    "\n",
    "It is interesting for you if you want to do the following:\n",
    "1. Find **performance issues** of your machine learning model.\n",
    "2. Find **anomalies and inconsistencies** in your data.\n",
    "3. Quickly **explore** your data using an interactive report to generate **insights**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook install and import sliceguard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sliceguard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sliceguard import SliceGuard\n",
    "from sliceguard.data import from_huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now download the demo dataset with our utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = from_huggingface(\"Matthijs/snacks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have the following dataframe containing an image column with a path to the raw image on the harddrive, a label and a split marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>apple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>apple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>apple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>apple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>apple</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>watermelon</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>watermelon</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>watermelon</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>watermelon</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>/home/daniel/.cache/huggingface/datasets/downl...</td>\n",
       "      <td>watermelon</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6745 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 image       label       split\n",
       "0    /home/daniel/.cache/huggingface/datasets/downl...       apple       train\n",
       "1    /home/daniel/.cache/huggingface/datasets/downl...       apple       train\n",
       "2    /home/daniel/.cache/huggingface/datasets/downl...       apple       train\n",
       "3    /home/daniel/.cache/huggingface/datasets/downl...       apple       train\n",
       "4    /home/daniel/.cache/huggingface/datasets/downl...       apple       train\n",
       "..                                                 ...         ...         ...\n",
       "950  /home/daniel/.cache/huggingface/datasets/downl...  watermelon  validation\n",
       "951  /home/daniel/.cache/huggingface/datasets/downl...  watermelon  validation\n",
       "952  /home/daniel/.cache/huggingface/datasets/downl...  watermelon  validation\n",
       "953  /home/daniel/.cache/huggingface/datasets/downl...  watermelon  validation\n",
       "954  /home/daniel/.cache/huggingface/datasets/downl...  watermelon  validation\n",
       "\n",
       "[6745 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for larger error groups and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature image was inferred as referring to raw data. If this is not the case, please specify in feature_types!\n",
      "Using default model for computing embeddings for feature image.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/code/sliceguard/.venv/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6508d1a8939d4cc89f0856163734bb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6745 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You didn't supply ground-truth labels and predictions. Will fit outlier detection model to find anomal slices instead.\n",
      "The overall metric value is 0.4790081435851741\n",
      "For outlier detection mode metric_mode will be set to min if not specified otherwise.\n",
      "Using 20 as maximum slice number to return.\n",
      "Using drop as sorting criterion for the slices to return.\n",
      "        metric  support      drop  level  drop+support\n",
      "1343  0.639310        3  0.160302      4      0.480906\n",
      "1363  0.638014        3  0.159006      4      0.477017\n",
      "1326  0.637582        2  0.158574      4      0.317148\n",
      "1370  0.637582        2  0.158574      4      0.317148\n",
      "1330  0.637367        2  0.158359      4      0.316717\n",
      "...        ...      ...       ...    ...           ...\n",
      "235   0.412520        3 -0.066488      4     -0.199464\n",
      "268   0.412320        4 -0.066688      4     -0.266752\n",
      "284   0.411953        3 -0.067055      4     -0.201165\n",
      "92    0.411787       11 -0.067221      3     -0.739433\n",
      "1087  0.410110        3 -0.068898      4     -0.206694\n",
      "\n",
      "[2299 rows x 5 columns]\n",
      "Identified 20 problematic slices.\n"
     ]
    }
   ],
   "source": [
    "sg = SliceGuard()\n",
    "issues = sg.find_issues(df, [\"image\"], drop_reference=\"parent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                 image       label  \\\n",
       " 0    /home/daniel/.cache/huggingface/datasets/downl...       apple   \n",
       " 1    /home/daniel/.cache/huggingface/datasets/downl...       apple   \n",
       " 2    /home/daniel/.cache/huggingface/datasets/downl...       apple   \n",
       " 3    /home/daniel/.cache/huggingface/datasets/downl...       apple   \n",
       " 4    /home/daniel/.cache/huggingface/datasets/downl...       apple   \n",
       " ..                                                 ...         ...   \n",
       " 950  /home/daniel/.cache/huggingface/datasets/downl...  watermelon   \n",
       " 951  /home/daniel/.cache/huggingface/datasets/downl...  watermelon   \n",
       " 952  /home/daniel/.cache/huggingface/datasets/downl...  watermelon   \n",
       " 953  /home/daniel/.cache/huggingface/datasets/downl...  watermelon   \n",
       " 954  /home/daniel/.cache/huggingface/datasets/downl...  watermelon   \n",
       " \n",
       "           split                                       sg_emb_image  sg_y_pred  \n",
       " 0         train  [0.12190916389226913, 0.2230367809534073, -0.1...   0.453254  \n",
       " 1         train  [0.9952030777931213, 1.1010890007019043, 1.403...   0.448683  \n",
       " 2         train  [0.4892514944076538, -0.743704080581665, -0.00...   0.449916  \n",
       " 3         train  [-0.4049392342567444, -1.0064574480056763, -0....   0.452626  \n",
       " 4         train  [-1.0221760272979736, 1.687761902809143, -1.11...   0.476017  \n",
       " ..          ...                                                ...        ...  \n",
       " 950  validation  [-1.590572714805603, -0.48898282647132874, 0.9...   0.485260  \n",
       " 951  validation  [-0.8258783221244812, 1.637852668762207, -0.97...   0.500751  \n",
       " 952  validation  [0.12347184866666794, -0.8151142597198486, 0.6...   0.486528  \n",
       " 953  validation  [-0.8118537664413452, -0.3193042278289795, -0....   0.485397  \n",
       " 954  validation  [-0.6673624515533447, 0.9910799860954285, -1.4...   0.486576  \n",
       " \n",
       " [6745 rows x 5 columns],\n",
       " [DataIssue(severity='medium', title='0.64 -> image, (1.00)', rows=[735, 3716, 3826, 5573, 6525], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.64 -> image, (1.00)', rows=[3771, 3825, 3836], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.64 -> image, (1.00)', rows=[754, 3805, 5592, 6544], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.64 -> image, (1.00)', rows=[3686, 3692], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.64 -> image, (1.00)', rows=[3697, 3831], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.64 -> image, (1.00)', rows=[733, 735, 738, 743, 751, 754, 3686, 3692, 3697, 3706, 3716, 3753, 3763, 3768, 3771, 3781, 3791, 3805, 3820, 3825, 3826, 3831, 3836, 5571, 5573, 5576, 5581, 5589, 5592, 6523, 6525, 6528, 6533, 6541, 6544], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.64 -> image, (1.00)', rows=[743, 3763, 5581, 6533], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.64 -> image, (1.00)', rows=[733, 751, 3781, 3791, 3820, 5571, 5589, 6523, 6541], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.64 -> image, (1.00)', rows=[738, 3706, 3753, 3768, 5576, 6528], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.61 -> image, (1.00)', rows=[3704, 3729, 3730, 3794], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.60 -> image, (1.00)', rows=[728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 972, 1507, 1538, 1647, 1669, 1710, 1713, 2803, 3685, 3686, 3687, 3689, 3691, 3692, 3693, 3695, 3697, 3698, 3699, 3700, 3701, 3703, 3704, 3705, 3706, 3708, 3709, 3710, 3711, 3712, 3713, 3714, 3716, 3719, 3720, 3721, 3723, 3724, 3725, 3726, 3727, 3728, 3729, 3730, 3731, 3732, 3733, 3734, 3735, 3736, 3737, 3738, 3739, 3740, 3741, 3742, 3743, 3744, 3746, 3747, 3748, 3749, 3750, 3751, 3752, 3753, 3754, 3755, 3756, 3757, 3758, 3759, 3760, 3761, 3762, 3763, 3764, 3765, 3766, 3767, 3768, 3769, 3770, 3771, 3772, 3773, 3774, 3775, 3776, 3778, 3779, 3780, 3781, 3782, 3783, 3784, 3785, 3786, 3787, 3788, 3789, 3790, 3791, 3792, 3793, 3794, 3796, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3805, 3806, 3807, 3808, 3809, 3810, 3811, 3812, 3813, 3814, 3815, 3816, 3817, 3818, 3819, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3828, 3829, 3830, 3831, 3833, 3834, 3835, 3836, 3837, 3838, 4597, 5566, 5567, 5568, 5569, 5570, 5571, 5572, 5573, 5574, 5575, 5576, 5577, 5578, 5579, 5580, 5581, 5582, 5583, 5584, 5585, 5586, 5587, 5588, 5589, 5590, 5591, 5592, 6518, 6519, 6520, 6521, 6522, 6523, 6524, 6525, 6526, 6527, 6528, 6529, 6530, 6531, 6532, 6533, 6534, 6535, 6536, 6537, 6538, 6539, 6540, 6541, 6542, 6543, 6544], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.60 -> image, (1.00)', rows=[736, 3739, 3752, 3835, 5574, 6526], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.60 -> image, (1.00)', rows=[3817, 3822], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.59 -> image, (1.00)', rows=[746, 748, 3725, 3827, 5584, 5586, 6536, 6538], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.59 -> image, (1.00)', rows=[743, 3783, 5581, 6533], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.59 -> image, (1.00)', rows=[748, 3693, 3721, 3784, 3812, 5586, 6538], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.59 -> image, (1.00)', rows=[736, 1669, 3708, 3739, 3752, 3835, 5574, 6526], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.59 -> image, (1.00)', rows=[740, 3709, 3732, 3750, 3773, 5578, 6530], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.59 -> image, (1.00)', rows=[752, 3743, 3829, 5590, 6542], columns=['image'], description=''),\n",
       "  DataIssue(severity='medium', title='0.59 -> image, (1.00)', rows=[740, 749, 3786, 5578, 5587, 6530, 6539], columns=['image'], description='')])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let sliceguard train a model to pinpoint problems even better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an own advanced model and find its weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
